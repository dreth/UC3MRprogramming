print('aaa')
print('aaaa')
set.seed(4)
n=10000
x=sample(seq(2,9998,by=2),n,replace=T)
plot(cumsum(x==1562)/(1:n),type="l")
abline(h=1/4999,col="red")
install.packages(’prob’,repos=’http://cran.rediris.es/’)
library(prob)
install.packages(’prob’,repos=’http://cran.rediris.es/’)
install.packages('prob',repos='http://cran.rediris.es/')
library(prob)
tosscoin(3)
library(prob)
probspace(tosscoin(1),probs=c(3/5,2/5))
tosscoin(1000)
help(tosscoin)
library(prob)
probspace(tosscoin(2),probs=c(3/5,2/5))
set.seed(35608261)
tosscoin(1000)
library(prob)
S=probspace(tosscoin(2),probs=c(3/5,2/5))
set.seed(35608261)
tosscoin(2)
plot(cumsum(sim(S,ntrials=1000)=="H")/(1:1000),
type="l",ylab="H freq",xlab="n toss")
abline(h=0.6,col="red")
library(prob)
S=probspace(tosscoin(2),probs=c(3/5,2/5))
set.seed(35608261)
plot(cumsum(sim(S,ntrials=1000)=="H")/(1:1000),
type="l",ylab="H freq",xlab="n toss")
abline(h=0.6,col="red")
library(prob)
S=probspace(tosscoin(1),probs=c(3/5,2/5))
set.seed(35608261)
plot(cumsum(sim(S,ntrials=1000)=="H")/(1:1000),
type="l",ylab="H freq",xlab="n toss")
abline(h=0.6,col="red")
sim(probspace(tosscoin(2),probs=c(3/5,2/5)),ntrials=1000)=="H")
sim(probspace(tosscoin(2),probs=c(3/5,2/5)),ntrials=1000)=="H"
sim(probspace(tosscoin(2),probs=c(3/5,2/5)),ntrials=10)
type('1')
library(prob)
S=probspace(tosscoin(2),probs=c(3/5,2/5))
set.seed(35608261)
data = sim(S,ntrials=1000)
S
data
S<-probspace(tosscoin(2),probs=c(3/5,2/5))
set.seed(35608261)
data <- sim(S,ntrials=1000)
data
clear
library(prob)
S<-probspace(tosscoin(2),probs=c(3/5,2/5))
set.seed(35608261)
data<-sim(S,ntrials=1000)
data
data$toss3 <- data$toss1 + data$toss2
data$toss3 <- paste(data$toss1,data$toss2,sep='_')
data[5]
head(data)
S<-probspace(tosscoin(2),probs=c(3/5,2/5))
set.seed(35608261)
data<-sim(S,ntrials=1000)
data$t1_t2 <- paste(data$toss1,data$toss2,sep='_')
barplot(data$t1_t2, main="Car Distribution",
xlab="Number of Gears")
library(prob)
library(dplyr)
S<-probspace(tosscoin(2),probs=c(3/5,2/5))
set.seed(35608261)
data<-sim(S,ntrials=1000)
data$t1_t2 <- paste(data$toss1,data$toss2,sep='_')
count <- dpylr::count(data$t1_t2)
install.packages('dpylr')
count <- dplyr::count(data$t1_t2)
library(dplyr)
install.packages('dpylr')
available.packages()
View(available.packages())
"dplyr" %in% rownames(available.packages())
library(dplyr)
library(dplyr)
install.packages("dplyr")
library(prob)
library(dplyr)
S<-probspace(tosscoin(2),probs=c(3/5,2/5))
set.seed(35608261)
data<-sim(S,ntrials=1000)
data$t1_t2 <- paste(data$toss1,data$toss2,sep='_')
count <- dplyr::count(data$t1_t2)
head(data)
count <- dplyr::count(data, t1_t2)
count
barplot(count)
barplot(count, main="t1_t2")
barplot(table(count))
table(count)
(0.6)*(0.02)+(O.04)*(0.4)
(-36/3)+7
9*7
(63/3)-11
pnorm(0.9)
pnorm(0.9) - pnorm(-0.9)
pnorm(0.9, lower.tail=FALSE)
1- 2*(pnorm(0.9, lower.tail=FALSE))
qnorm(0.95)
qnorm(0.025)
qnorm(-0.025)
qnorm(0.975)
qnorm(0.975)/0.3
(qnorm(0.975)/0.3)^2
chisq(0.9, 9)
qchisq(0.9, 9)
qchisq(0.05, 9, lower.tail = TRUE)
qchisq(0.05, 9, lower.tail = FALSE)
qchisq(0.95, 9, lower.tail = FALSE)
3.33/9
16.92/9
pt(2, 5)
pt(-2, 5) - pt(2,5)
pt(2, 5) - pt(-2,5)
pt(-2,5)
qf(0.95,5,9)
df = read.table("https://s3.amazonaws.com/assets.datacamp.com/blog_assets/scores_timed.txt",
header=FALSE, sep="/", strip.white=TRUE, na.strings="EMPTY")
print(df)
df = read.csv("https://s3.amazonaws.com/assets.datacamp.com/blog_assets/scores_timed.csv",
header=TRUE, quote="\"", stringsAsFactors=TRUE, strip.white=TRUE)
print(df)
df = read.csv2("https://s3.amazonaws.com/assets.datacamp.com/blog_assets/scores_timed2.csv",
header = FALSE,
quote = "\"",
dec = ",",
row.names = c("M", "N", "O", "P", "Q"),
col.names= c("X", "Y", "Z", "A","B"),
fill = TRUE,
strip.white = TRUE,
stringsAsFactors=TRUE)
print(df)
# Check the type of data
str(df)
options(repos=c(CRAN="http://cran.rstudio.com"))
if (!require(DAAG)) install.packages("DAAG")
library(DAAG)
if (!require(dplyr)) install.packages("dplyr")
library(dplyr)
if (!require(data.table)) install.packages("data.table")
head(headInjury)
data = headInjury
dim(data)
names(data)
class(data)
data = cbind(1:nrow(data), data)
colnames(data)[1] = "number"
data_sub = select(data,1:3)
head(data_sub)
var_temp = names(data)[4:6]
data_sub = select(data, high.risk:vomiting)
head(data_sub)
data_sub = select(data, -(high.risk:vomiting))
head(data_sub)
i = match("high.risk", names(data))
j = match("vomiting", names(data))
data_sub = data[, -(i:j)]
var_logical = TRUE
class(var_logical)
clear all
exit
restart
quit
quit()
library(VIM)
library(caret)
library(fastDummies)
library(dplyr)
library(RANN)
library(MLeval)
library(caretEnsemble)
df=read.csv("C:/Users/ander/OneDrive/Escritorio/Master/Programming/titanic.csv",na.strings = c("",NA))
g=read.csv("C:/Users/ander/OneDrive/Escritorio/Master/Programming/gender_submission.csv",na.strings = c("",NA))
library(VIM)
library(caret)
library(fastDummies)
library(dplyr)
library(RANN)
library(MLeval)
library(caretEnsemble)
df=read.csv("./data/titanic.csv",na.strings = c("",NA))
library(VIM)
library(caret)
library(fastDummies)
library(dplyr)
library(RANN)
library(MLeval)
library(caretEnsemble)
setwd('/home/dreth/.local/share/Cryptomator/mnt/qO7BgnSQeH87_1/UC3M/COURSES/Programming in R/UC3MRprogramming/')
df=read.csv("./data/titanic.csv",na.strings = c("",NA))
g=read.csv("./data/gender_submission.csv",na.strings = c("",NA))
for (i in g$PassengerId[1]:g$PassengerId[length(g$PassengerId)]){
df$Survived[i]=g$Survived[i-891]
}
#Remove columns that we are not going to use.
df[df$Embarked==" "]<-NA
df=df[,-(4)]
df=df[,-(6:8)]
df=df[,-(7)]
#Define classes as character:
df$Pclass=as.character(df$Pclass)
df$Sex<-replace(df$Sex,df$Sex=='male',0)
df$Sex<-replace(df$Sex,df$Sex=='female',1)
df$Survived<-replace(df$Survived,df$Survived==1,'YES')
df$Survived<-replace(df$Survived,df$Survived==0,'NO')
df$Survived=as.factor(df$Survived)
df$Sex=as.factor(df$Sex)
str(df)
#Preprocess: Remove NAs using K-nearest neighbours
df=kNN(df,variable=c("Embarked","Age","Fare"))
df=df[,-(8:10)]
anyNA(df)
#One hot encoding (Dummy variables) of character variables:
df=dummy_cols(df,select_columns = c('Pclass','Embarked'))
df=df[,-c(3,7)]
#Create partition:
n=createDataPartition(df$PassengerId,p=0.8,list=FALSE)
train=df[n,]
train=df[,-1]
test=df[-n,]
#Store x and y for using them:
x_train=train[,(2:10)]
y_train=train$Survived
#Analysis of variables:
analy = x_train
apply(analy[,c(2,3)], 2, FUN=function(x){c('min'=min(x), 'max'=max(x))})
featurePlot(x = train[,(2:10)],
y = train$Survived,
plot = "box",
strip=strip.custom(par.strip.text=list(cex=.7)),
scales = list(x = list(relation="free"),
y = list(relation="free")))
set.seed(613)
options(warn = -1)
subsets = 1:9
ctrl = rfeControl(functions = rfFuncs, method = "repeatedcv", repeats = 5, verbose = FALSE)
lmProfile = rfe(x = x_train, y = y_train, sizes = subsets, rfeControl = ctrl,metric="Accuracy")
lmProfile
library(caretEnsemble)
setwd('/home/dreth/.local/share/Cryptomator/mnt/qO7BgnSQeH87_1/UC3M/COURSES/Programming in R/UC3MRprogramming/')
df=read.csv("./data/titanic.csv",na.strings = c("",NA))
g=read.csv("./data/gender_submission.csv",na.strings = c("",NA))
for (i in g$PassengerId[1]:g$PassengerId[length(g$PassengerId)]){
df$Survived[i]=g$Survived[i-891]
}
#Remove columns that we are not going to use.
df[df$Embarked==" "]<-NA
df=df[,-(4)]
df=df[,-(6:8)]
df=df[,-(7)]
#Define classes as character:
df$Pclass=as.character(df$Pclass)
library(VIM)
library(caret)
library(fastDummies)
library(dplyr)
library(RANN)
library(MLeval)
library(caretEnsemble)
setwd('/home/dreth/.local/share/Cryptomator/mnt/qO7BgnSQeH87_1/UC3M/COURSES/Programming in R/UC3MRprogramming/')
df=read.csv("./data/titanic.csv",na.strings = c("",NA))
g=read.csv("./data/gender_submission.csv",na.strings = c("",NA))
for (i in g$PassengerId[1]:g$PassengerId[length(g$PassengerId)]){
df$Survived[i]=g$Survived[i-891]
}
#Remove columns that we are not going to use.
df[df$Embarked==" "]<-NA
df=df[,-(4)]
df=df[,-(6:8)]
library(VIM)
library(caret)
library(fastDummies)
library(dplyr)
library(RANN)
library(MLeval)
library(caretEnsemble)
setwd('/home/dreth/.local/share/Cryptomator/mnt/qO7BgnSQeH87_1/UC3M/COURSES/Programming in R/UC3MRprogramming/')
df=read.csv("./data/titanic.csv",na.strings = c("",NA))
g=read.csv("./data/gender_submission.csv",na.strings = c("",NA))
for (i in g$PassengerId[1]:g$PassengerId[length(g$PassengerId)]){
df$Survived[i]=g$Survived[i-891]
}
#Remove columns that we are not going to use.
df[df$Embarked==" "]<-NA
df=df[,-(4)]
df=df[,-(6:8)]
#Remove columns that we are not going to use.
df$Embarked <- ifelse(!is.na(df$Embarked) & df$Embarked == " ", NA, df$Embarked)
library(VIM)
library(caret)
library(fastDummies)
library(dplyr)
library(RANN)
library(MLeval)
library(caretEnsemble)
setwd('/home/dreth/.local/share/Cryptomator/mnt/qO7BgnSQeH87_1/UC3M/COURSES/Programming in R/UC3MRprogramming/')
df=read.csv("./data/titanic.csv",na.strings = c("",NA))
g=read.csv("./data/gender_submission.csv",na.strings = c("",NA))
for (i in g$PassengerId[1]:g$PassengerId[length(g$PassengerId)]){
df$Survived[i]=g$Survived[i-891]
}
#Remove columns that we are not going to use.
df$Embarked <- ifelse(!is.na(df$Embarked) & df$Embarked == " ", NA, df$Embarked)
df=df[,-(4)]
df=df[,-(6:8)]
df=df[,-(7)]
#Define classes as character:
df$Pclass=as.character(df$Pclass)
df$Sex<-replace(df$Sex,df$Sex=='male',0)
df$Sex<-replace(df$Sex,df$Sex=='female',1)
df$Survived<-replace(df$Survived,df$Survived==1,'YES')
df$Survived<-replace(df$Survived,df$Survived==0,'NO')
df$Survived=as.factor(df$Survived)
df$Sex=as.factor(df$Sex)
str(df)
#Preprocess: Remove NAs using K-nearest neighbours
df=kNN(df,variable=c("Embarked","Age","Fare"))
df=df[,-(8:10)]
anyNA(df)
#One hot encoding (Dummy variables) of character variables:
df=dummy_cols(df,select_columns = c('Pclass','Embarked'))
df=df[,-c(3,7)]
#Create partition:
n=createDataPartition(df$PassengerId,p=0.8,list=FALSE)
train=df[n,]
train=df[,-1]
test=df[-n,]
#Store x and y for using them:
x_train=train[,(2:10)]
y_train=train$Survived
#Analysis of variables:
analy = x_train
apply(analy[,c(2,3)], 2, FUN=function(x){c('min'=min(x), 'max'=max(x))})
featurePlot(x = train[,(2:10)],
y = train$Survived,
plot = "box",
strip=strip.custom(par.strip.text=list(cex=.7)),
scales = list(x = list(relation="free"),
y = list(relation="free")))
library(VIM)
library(caret)
library(fastDummies)
library(dplyr)
library(RANN)
library(MLeval)
library(caretEnsemble)
setwd('/home/dreth/.local/share/Cryptomator/mnt/qO7BgnSQeH87_1/UC3M/COURSES/Programming in R/UC3MRprogramming/')
df=read.csv("./data/titanic.csv",na.strings = c("",NA))
g=read.csv("./data/gender_submission.csv",na.strings = c("",NA))
for (i in g$PassengerId[1]:g$PassengerId[length(g$PassengerId)]){
df$Survived[i]=g$Survived[i-891]
}
#Remove columns that we are not going to use.
df$Embarked <- ifelse(!is.na(df$Embarked) & df$Embarked == " ", NA, df$Embarked)
df=df[,-(4)]
df=df[,-(6:8)]
df=df[,-(7)]
#Define classes as character:
df$Pclass=as.character(df$Pclass)
df$Sex<-replace(df$Sex,df$Sex=='male',0)
df$Sex<-replace(df$Sex,df$Sex=='female',1)
df$Survived<-replace(df$Survived,df$Survived==1,'YES')
df$Survived<-replace(df$Survived,df$Survived==0,'NO')
df$Survived=as.factor(df$Survived)
df$Sex=as.factor(df$Sex)
str(df)
#Preprocess: Remove NAs using K-nearest neighbours
df=kNN(df,variable=c("Embarked","Age","Fare"))
df=df[,-(8:10)]
anyNA(df)
#One hot encoding (Dummy variables) of character variables:
df=dummy_cols(df,select_columns = c('Pclass','Embarked'))
df=df[,-c(3,7)]
#Create partition:
n=createDataPartition(df$PassengerId,p=0.8,list=FALSE)
train=df[n,]
train=df[,-1]
test=df[-n,]
#Store x and y for using them:
x_train=train[,(2:10)]
y_train=train$Survived
#Analysis of variables:
analy = x_train
apply(analy[,c(2,3)], 2, FUN=function(x){c('min'=min(x), 'max'=max(x))})
featurePlot(x = train[,(2:10)],
y = train$Survived,
plot = "box",
strip=strip.custom(par.strip.text=list(cex=.7)),
scales = list(x = list(relation="free"),
y = list(relation="free")))
analy
featurePlot(x = train[,(2:10)],
y = train$Survived,
plot = "box",
strip=strip.custom(par.strip.text=list(cex=.7)),
scales = list(x = list(relation="free"),
y = list(relation="free")))
#Analysis of variables:
analy = x_train
apply(analy[,c(2,3)], 2, FUN=function(x){c('min'=min(x), 'max'=max(x))})
set.seed(613)
options(warn = -1)
subsets = 1:9
ctrl = rfeControl(functions = rfFuncs, method = "repeatedcv", repeats = 5, verbose = FALSE)
lmProfile = rfe(x = x_train, y = y_train, sizes = subsets, rfeControl = ctrl,metric="Accuracy")
lmProfile
#Model fitting and predicting:
ctrl= trainControl(method='repeatedcv', number=5, savePredictions='final', classProbs=T, summaryFunction=twoClassSummary)
train_mars=train(Survived~.,data=train,method="earth",metric='accuracy',trControl=ctrl)
library(VIM)
library(caret)
library(fastDummies)
library(dplyr)
library(RANN)
library(MLeval)
library(caretEnsemble)
setwd('/home/dreth/.local/share/Cryptomator/mnt/qO7BgnSQeH87_1/UC3M/COURSES/Programming in R/UC3MRprogramming/')
df=read.csv("./data/titanic.csv",na.strings = c("",NA))
g=read.csv("./data/gender_submission.csv",na.strings = c("",NA))
for (i in g$PassengerId[1]:g$PassengerId[length(g$PassengerId)]){
df$Survived[i]=g$Survived[i-891]
}
#Remove columns that we are not going to use.
df$Embarked <- ifelse(!is.na(df$Embarked) & df$Embarked == " ", NA, df$Embarked)
df=df[,-(4)]
df=df[,-(6:8)]
df=df[,-(7)]
#Define classes as character:
df$Pclass=as.character(df$Pclass)
df$Sex<-replace(df$Sex,df$Sex=='male',0)
df$Sex<-replace(df$Sex,df$Sex=='female',1)
df$Survived<-replace(df$Survived,df$Survived==1,'YES')
df$Survived<-replace(df$Survived,df$Survived==0,'NO')
df$Survived=as.factor(df$Survived)
df$Sex=as.factor(df$Sex)
str(df)
#Preprocess: Remove NAs using K-nearest neighbours
df=kNN(df,variable=c("Embarked","Age","Fare"))
df=df[,-(8:10)]
anyNA(df)
#One hot encoding (Dummy variables) of character variables:
df=dummy_cols(df,select_columns = c('Pclass','Embarked'))
df=df[,-c(3,7)]
#Create partition:
n=createDataPartition(df$PassengerId,p=0.8,list=FALSE)
train=df[n,]
train=df[,-1]
test=df[-n,]
#Store x and y for using them:
x_train=train[,(2:10)]
y_train=train$Survived
#Analysis of variables:
analy = x_train
apply(analy[,c(2,3)], 2, FUN=function(x){c('min'=min(x), 'max'=max(x))})
set.seed(613)
options(warn = -1)
subsets = 1:9
ctrl = rfeControl(functions = rfFuncs, method = "repeatedcv", repeats = 5, verbose = FALSE)
lmProfile = rfe(x = x_train, y = y_train, sizes = subsets, rfeControl = ctrl,metric="Accuracy")
lmProfile
#Model fitting and predicting:
ctrl= trainControl(method='repeatedcv', number=5, savePredictions='final', classProbs=T, summaryFunction=twoClassSummary)
train_mars=train(Survived~.,data=train,method="earth",metric='accuracy',trControl=ctrl)
#Model fitting and predicting:
ctrl= trainControl(method='repeatedcv', number=5, savePredictions='final', classProbs=T, summaryFunction=twoClassSummary)
train_mars=train(Survived~.,data=train,method="earth",metric='accuracy',trControl=ctrl)
train_mars
p_mars=predict(train_mars,test)
confusionMatrix(reference=test$Survived,data=p_mars,mode="everything",positive = "YES")
roc_mars = evalm(train_mars)$roc
train_rf=train(Survived~.,data=train,method="rf",metric='ROC',trControl=ctrl)
exit
exit()
quit
quit()
#3
qnorm(0.15,5.86,1.88)
